{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luensmann/Bachelorarbeit/blob/main/Pre%20Processing/raw2ibo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f7b0ce-c3da-48b0-aa2b-47d1e21e2dd2",
      "metadata": {
        "tags": [],
        "id": "06f7b0ce-c3da-48b0-aa2b-47d1e21e2dd2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import json\n",
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aaa3004-5ebb-4140-b5e6-5bcc2f8d7662",
      "metadata": {
        "tags": [],
        "id": "4aaa3004-5ebb-4140-b5e6-5bcc2f8d7662"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = Tokenizer(nlp.vocab, token_match=re.compile(r'\\S+').match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e3a7e4-c558-441c-8da1-6ead7fb5d13c",
      "metadata": {
        "tags": [],
        "id": "89e3a7e4-c558-441c-8da1-6ead7fb5d13c"
      },
      "outputs": [],
      "source": [
        "def open_doc(filename):\n",
        "    with open(filename) as f:\n",
        "        corpus = json.load(f)\n",
        "    f.close\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bad690a-4bda-4c00-b4b8-0143a5c0184a",
      "metadata": {
        "tags": [],
        "id": "6bad690a-4bda-4c00-b4b8-0143a5c0184a"
      },
      "outputs": [],
      "source": [
        "def write_doc(data, filename):\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d534cd-f3ae-4d06-81f3-7bc2622e3331",
      "metadata": {
        "tags": [],
        "id": "93d534cd-f3ae-4d06-81f3-7bc2622e3331"
      },
      "outputs": [],
      "source": [
        "def get_entTypes(docEntity):\n",
        "    entTypes = []\n",
        "    for ent in docEntity:\n",
        "        entTypes.append(ent[\"type\"])\n",
        "    return entTypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11161fae-e1d7-49f7-92bf-0ea9e90b54df",
      "metadata": {
        "id": "11161fae-e1d7-49f7-92bf-0ea9e90b54df"
      },
      "outputs": [],
      "source": [
        "def get_entLim(docEnts):\n",
        "    entLim = []\n",
        "    \n",
        "    for ent in docEnts:\n",
        "        entLim.append(ent[\"begin\"])\n",
        "        entLim.append(ent[\"end\"])\n",
        "    return entLim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a667a947-dc97-49af-a4fd-2f3ae02612d6",
      "metadata": {
        "tags": [],
        "id": "a667a947-dc97-49af-a4fd-2f3ae02612d6"
      },
      "outputs": [],
      "source": [
        "def get_entTxt(docEnts):\n",
        "    entTxt = []\n",
        "    \n",
        "    for ent in docEnts:\n",
        "        entTxt.append(ent[\"text\"])\n",
        "    return entTxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e212d2-0a00-48bb-a4aa-4b4193eb83f8",
      "metadata": {
        "tags": [],
        "id": "34e212d2-0a00-48bb-a4aa-4b4193eb83f8"
      },
      "outputs": [],
      "source": [
        "def split_text(docText, entLim):\n",
        "    parts = list(docText[i:j] for i,j in zip(entLim, entLim[1:]+[None]))\n",
        "    if(len(entLim) > 0 and entLim[0] != 0):\n",
        "        parts.insert(0, docText[0:entLim[0]])\n",
        "    return parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f4b18c-de8e-4253-b1f7-5857b8b0773d",
      "metadata": {
        "tags": [],
        "id": "82f4b18c-de8e-4253-b1f7-5857b8b0773d"
      },
      "outputs": [],
      "source": [
        "def sync_nerTags(nerTags, splts, entTxt, entTypes):\n",
        "    entCnt = 0\n",
        "    for splt in range(len(splts)):\n",
        "        if(splts[splt] == entTxt[entCnt]):\n",
        "            nerTags[splt] = entTypes[entCnt]\n",
        "            if(entCnt < len(entTypes)-1):\n",
        "                entCnt += 1\n",
        "        else: \n",
        "            nerTags[splt] = \"O\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71fd20e5-f89d-434e-959b-1276b578f753",
      "metadata": {
        "tags": [],
        "id": "71fd20e5-f89d-434e-959b-1276b578f753"
      },
      "outputs": [],
      "source": [
        "def txt2json(splts, docTxt, nerTags, docID):\n",
        "    id = docID\n",
        "    tkns = []\n",
        "    ner_tags2 = []  \n",
        "\n",
        "    if(len(splts) == 0):\n",
        "        doc = nlp.tokenizer(docTxt)\n",
        "        for tkn in doc:\n",
        "            tkns.append(str(tkn))\n",
        "            ner_tags2.append(0)\n",
        "        output = {\"id\": id, \"raw_text\": docTxt, \"token\": tkns, \"ner_tags\": ner_tags2}\n",
        "        return output\n",
        "    \n",
        "    for splt in range(len(splts)):\n",
        "        doc = nlp.tokenizer(splts[splt])\n",
        "        \n",
        "        for tkn in range(len(doc)):\n",
        "            tkns.append(str(doc[tkn]))\n",
        "            if(nerTags[splt] != \"O\"):\n",
        "                if(tkn == 0):\n",
        "                    ner_tags2.append(label2id[\"B-\" + nerTags[splt]])\n",
        "                else:\n",
        "                    ner_tags2.append(label2id[\"I-\" + nerTags[splt]])\n",
        "            else:\n",
        "                ner_tags2.append(0)     \n",
        "    \n",
        "    output = {\"id\": id, \"raw_text\": docTxt, \"token\": tkns, \"ner_tags\": ner_tags2}\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "labels_Variome = ['O', 'B-disease', 'I-disease', 'B-body-part', 'I-body-part', 'B-mutation', 'I-mutation', 'B-Physiology', 'I-Physiology', 'B-cohort-patient', 'I-cohort-patient', 'B-size', 'I-size', 'B-gender', 'I-gender', 'B-age', 'I-age', 'B-Concepts_Ideas', 'I-Concepts_Ideas', 'B-Disorder', 'I-Disorder', 'B-gene', 'I-gene', 'B-Phenomena', 'I-Phenomena', 'B-ethnicity', 'I-ethnicity']\n",
        "labels_Amia = ['O', 'B-Gene_protein', 'I-Gene_protein', 'B-DNA_Mutation', 'I-DNA_Mutation', 'B-DNA_modification', 'I-DNA_modification', 'B-locus', 'I-locus', 'B-Mutation', 'I-Mutation', 'B-dbSNP', 'I-dbSNP', 'B-Protein_Mutation', 'I-Protein_Mutation', 'B-RNA', 'I-RNA', 'B-RNA_Mutation', 'I-RNA_Mutation']\n",
        "labels_SETH = ['O', 'B-Gene', 'I-Gene', 'B-SNP', 'I-SNP', 'B-RS', 'I-RS']\n",
        "labels_tmvar = ['O', 'B-DNAMutation', 'I-DNAMutation', 'B-ProteinMutation', 'I-ProteinMutation', 'B-SNP', 'I-SNP']\n",
        "\n",
        "\n",
        "#labels = ['disease', 'body-part', 'mutation', 'Physiology', 'cohort-patient', 'size', 'gender', 'age', 'Concepts_Ideas', 'Disorder', 'gene', 'Phenomena', 'ethnicity'] # Variome\n",
        "#labels = ['Gene_protein', 'DNA_Mutation', 'DNA_modification', 'locus', 'Mutation', 'dbSNP', 'Protein_Mutation', 'RNA', 'RNA_Mutation'] # Amia\n",
        "#labels = ['Gene', 'SNP', 'RS'] # SETH\n",
        "#labels = ['DNAMutation', 'ProteinMutation', 'SNP'] # tmvar\n",
        "labels = [['DNAMutation', 'ProteinMutation', 'SNP'], ['Gene', 'SNP', 'RS'], ['Gene_protein', 'DNA_Mutation', 'DNA_modification', 'locus', 'Mutation', 'dbSNP', 'Protein_Mutation', 'RNA', 'RNA_Mutation'], ['disease', 'body-part', 'mutation', 'Physiology', 'cohort-patient', 'size', 'gender', 'age', 'Concepts_Ideas', 'Disorder', 'gene', 'Phenomena', 'ethnicity']]\n",
        "\n",
        "label_names = [\"O\"]\n",
        "for label in labels:\n",
        "    label_names.append(\"B-\" + label)\n",
        "    label_names.append(\"I-\" + label)\n",
        "\n",
        "print(label_names)\n",
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "'''"
      ],
      "metadata": {
        "id": "IDOI90xXhqym"
      },
      "id": "IDOI90xXhqym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071a8d35-30ba-4917-82f3-5af61d582f4f",
      "metadata": {
        "id": "071a8d35-30ba-4917-82f3-5af61d582f4f"
      },
      "outputs": [],
      "source": [
        "def get_labels(docNum):\n",
        "    labels = [['DNAMutation', 'ProteinMutation', 'SNP'], ['Gene', 'SNP', 'RS'], ['Gene_protein', 'DNA_Mutation', 'DNA_modification', 'locus', 'Mutation', 'dbSNP', 'Protein_Mutation', 'RNA', 'RNA_Mutation'], ['disease', 'body-part', 'mutation', 'Physiology', 'cohort-patient', 'size', 'gender', 'age', 'Concepts_Ideas', 'Disorder', 'gene', 'Phenomena', 'ethnicity']]\n",
        "    label_names = [\"O\"]\n",
        "    for label in labels[docNum]:\n",
        "        label_names.append(\"B-\" + label)\n",
        "        label_names.append(\"I-\" + label)\n",
        "    print(label_names)\n",
        "    return(label_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1876f7a-9f61-4d26-9b61-c52dc06f9dea",
      "metadata": {
        "tags": [],
        "id": "b1876f7a-9f61-4d26-9b61-c52dc06f9dea"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "label_names = get_labels(0)\n",
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "pprint.pprint(label2id)\n",
        "pprint.pprint(id2label)\n",
        "for label in label2id:\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d6a84c7-1f11-4da4-98f2-f69780df3933",
      "metadata": {
        "tags": [],
        "id": "1d6a84c7-1f11-4da4-98f2-f69780df3933"
      },
      "outputs": [],
      "source": [
        "tmvar = ['tmvar-train', 'tmvar-test'] # 0\n",
        "SETH = ['SETH-train', 'SETH-test'] # 1\n",
        "amia = ['amia-train', 'amia-test'] # 2\n",
        "Variome = ['Variome-train', 'Variome-test'] # 3\n",
        "corpora = [ ['tmvar-train', 'tmvar-test'], ['SETH-train', 'SETH-test'], ['amia-train', 'amia-test'], ['Variome-train', 'Variome-test']]\n",
        "\n",
        "for docNum in range(4):\n",
        "    label_names = get_labels(docNum)\n",
        "    id2label = {i: label for i, label in enumerate(label_names)}\n",
        "    label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "    for doc in corpora[docNum]:\n",
        "        print('corpus name:' + doc)\n",
        "        corpus = open_doc(doc + '.json')\n",
        "        jsonOut = []\n",
        "        filename = doc\n",
        "        fOut = doc + '-ibo.json'\n",
        "        all_Ents = []\n",
        "        for document in corpus[\"documents\"]:\n",
        "            docID = document[\"document\"][\"ID\"]\n",
        "            docText = document[\"document\"][\"text\"]\n",
        "            docEnts = document[\"document\"][\"entities\"]\n",
        "\n",
        "            entLim = get_entLim(docEnts)\n",
        "            entTypes = get_entTypes(docEnts)\n",
        "\n",
        "            for ent in entTypes:\n",
        "                if ent not in all_Ents:\n",
        "                    all_Ents.append(ent)\n",
        "            entTxt = get_entTxt(docEnts)\n",
        "            splts = split_text(docText, entLim)\n",
        "            nerTags = [0] * len(splts)\n",
        "            sync_nerTags(nerTags, splts, entTxt, entTypes)\n",
        "            out = txt2json(splts, docText, nerTags, docID)\n",
        "            jsonOut.append(out)\n",
        "        print(len(jsonOut))\n",
        "        for i in range(len(jsonOut)):\n",
        "\n",
        "            print(\"#\" + jsonOut[i][\"id\"])\n",
        "            for tag in range(len(jsonOut[i][\"ner_tags\"])):\n",
        "                if(jsonOut[i][\"ner_tags\"][tag] != 0):\n",
        "\n",
        "                    print(jsonOut[i][\"token\"][tag], jsonOut[i][\"ner_tags\"][tag])\n",
        "            print(\"\\n\")\n",
        "    \n",
        "        print('found ents:', all_Ents)\n",
        "        write_doc(jsonOut, fOut)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}